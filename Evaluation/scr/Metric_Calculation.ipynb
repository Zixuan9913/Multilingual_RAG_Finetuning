{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "29da425df850406789b4b9558465e7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da38733309d6435a99c3f92d439acf18",
              "IPY_MODEL_597864d2094d4e73b4ce61dc9a86b4f6",
              "IPY_MODEL_911f74e3f0fd46f1ae454f08ed40d001"
            ],
            "layout": "IPY_MODEL_cebc2c4f8374463b90e8d5115b34a91c"
          }
        },
        "da38733309d6435a99c3f92d439acf18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3335c9516b644649a0b7e624154fc0eb",
            "placeholder": "​",
            "style": "IPY_MODEL_f43a84ee3047430b8da25ad8415c77cc",
            "value": "Processing: 100%"
          }
        },
        "597864d2094d4e73b4ce61dc9a86b4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f48b62e5c494b0ca964775c63afe879",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fff42b7617b74b459b11df77bd6bde03",
            "value": 160
          }
        },
        "911f74e3f0fd46f1ae454f08ed40d001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31daaa6c2d7d4175bd9bdeba297d0310",
            "placeholder": "​",
            "style": "IPY_MODEL_2f928fa805ad41d7bc5f11f40d00f0bf",
            "value": " 160/160 [13:48&lt;00:00,  4.34s/it]"
          }
        },
        "cebc2c4f8374463b90e8d5115b34a91c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3335c9516b644649a0b7e624154fc0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43a84ee3047430b8da25ad8415c77cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f48b62e5c494b0ca964775c63afe879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff42b7617b74b459b11df77bd6bde03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31daaa6c2d7d4175bd9bdeba297d0310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f928fa805ad41d7bc5f11f40d00f0bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0dzW-Po_RM3",
        "outputId": "92621c5e-87b3-4a2e-9955-dee7387b795f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install -q transformers torch pandas sentence-transformers bert-score tensorflow tensorflow-text tensorflow-hub sacrebleu nltk\n",
        "\n",
        "# Second Cell - Import libraries and download NLTK data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from bert_score import BERTScorer\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text\n",
        "from tqdm.notebook import tqdm\n",
        "from sacrebleu.metrics import BLEU\n",
        "import nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from transformers import MarianMTModel, MarianTokenizer,AutoTokenizer, AutoModel\n",
        "from transformers import pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#When the generated response is different than the gold answer language, we need to translate the response to the target language first\n",
        "\n",
        "source_lang = 'vi'\n",
        "target_lang = 'en'\n",
        "\n",
        "class HelsinkiTranslator:\n",
        "    def __init__(self, source_lang, target_lang):\n",
        "        \"\"\"\n",
        "        Initialize Helsinki NLP translator\n",
        "        source_lang and target_lang should be in ISO 639-1 format (e.g., 'en', 'de', 'fr')\n",
        "        \"\"\"\n",
        "        model_name = f'Helsinki-NLP/opus-mt-{source_lang}-{target_lang}'\n",
        "        print(f\"Loading translation model: {model_name}\")\n",
        "\n",
        "        try:\n",
        "            self.tokenizer =MarianTokenizer.from_pretrained(model_name)\n",
        "            self.model = MarianMTModel.from_pretrained(model_name)\n",
        "            self.translator = pipeline(\"translation\", model=self.model, tokenizer=self.tokenizer)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {model_name}: {str(e)}\")\n",
        "            print(\"Attempting to load alternative model path...\")\n",
        "            # Try alternative model path format\n",
        "            alt_model_name = f'Helsinki-NLP/opus-mt-{source_lang}+{source_lang}-{target_lang}+{target_lang}'\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(alt_model_name)\n",
        "            self.model = AutoModelForSeq2SeqGeneration.from_pretrained(alt_model_name)\n",
        "            self.translator = pipeline(\"translation\", model=self.model, tokenizer=self.tokenizer)\n",
        "\n",
        "    def translate(self, text):\n",
        "        \"\"\"Translate text using Helsinki NLP model\"\"\"\n",
        "        try:\n",
        "            result = self.translator(text, max_length=1024)\n",
        "            return result[0]['translation_text']\n",
        "        except Exception as e:\n",
        "            print(f\"Translation error: {str(e)}\")\n",
        "            return text\n",
        "\n",
        "class CrossLingualEvaluator:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize evaluation models\"\"\"\n",
        "        print(\"Loading evaluation models...\")\n",
        "\n",
        "        # Load Sentence-BERT\n",
        "        self.sbert = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
        "\n",
        "        # Load BERTScore\n",
        "        self.bert_scorer = BERTScorer(\n",
        "            model_type=\"xlm-roberta-large\",\n",
        "            num_layers=17,\n",
        "            rescale_with_baseline=False\n",
        "        )\n",
        "\n",
        "        # Initialize BLEU with smoothing\n",
        "        self.bleu = BLEU(smooth_method='exp')\n",
        "\n",
        "        print(\"Models loaded successfully!\")\n",
        "\n",
        "    def calculate_metrics(self, text1, text2):\n",
        "        \"\"\"Calculate all metrics for a pair of texts\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        # SBERT similarity\n",
        "        emb1 = self.sbert.encode(text1, convert_to_numpy=True)\n",
        "        emb2 = self.sbert.encode(text2, convert_to_numpy=True)\n",
        "        results['sbert_similarity'] = float(np.dot(emb1, emb2) /\n",
        "                                         (np.linalg.norm(emb1) * np.linalg.norm(emb2)))\n",
        "\n",
        "        # BERTScore\n",
        "        P, R, F1 = self.bert_scorer.score([text1], [text2])\n",
        "        results['bertscore_precision'] = float(P[0])\n",
        "        results['bertscore_recall'] = float(R[0])\n",
        "        results['bertscore_f1'] = float(F1[0])\n",
        "\n",
        "        # BLEU\n",
        "        results['bleu_score'] = self.bleu.corpus_score([text1], [[text2]]).score / 100.0\n",
        "\n",
        "        # METEOR\n",
        "        try:\n",
        "            results['meteor_score'] = meteor_score([text2.split()], text1.split())\n",
        "        except:\n",
        "            results['meteor_score'] = 0.0\n",
        "\n",
        "        return results\n",
        "\n",
        "# Fourth Cell - Evaluation function\n",
        "def evaluate_dataset(df, source_lang, target_lang, gen_col='generated_answer',\n",
        "                    gold_col='gold_answer', sample_size=None):\n",
        "    \"\"\"\n",
        "    Evaluate the dataset using Helsinki translation and multiple metrics\n",
        "    \"\"\"\n",
        "    # Initialize translator and evaluator\n",
        "    translator = HelsinkiTranslator(source_lang, target_lang)\n",
        "    evaluator = CrossLingualEvaluator()\n",
        "\n",
        "    # Sample dataset if specified\n",
        "    if sample_size and sample_size < len(df):\n",
        "        df = df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing\"):\n",
        "        try:\n",
        "            # Translate generated text\n",
        "            translated_gen = translator.translate(row[gen_col])\n",
        "\n",
        "            # Calculate metrics\n",
        "            metrics = evaluator.calculate_metrics(translated_gen, row[gold_col])\n",
        "            #metrics = evaluator.calculate_metrics(row[gen_col], row[gold_col])\n",
        "            # Store results\n",
        "            result = {\n",
        "                'original_generated': row[gen_col],\n",
        "                'translated_generated': translated_gen,\n",
        "                'gold_answer': row[gold_col],\n",
        "                **metrics\n",
        "            }\n",
        "            all_results.append(result)\n",
        "\n",
        "            # Print progress every 20 samples\n",
        "            if (idx + 1) % 20 == 0:\n",
        "                print(f\"\\nProcessed {idx + 1}/{len(df)} samples\")\n",
        "                print(\"Last sample results:\")\n",
        "                for metric, value in metrics.items():\n",
        "                    print(f\"{metric:20s}: {value:.4f}\")\n",
        "                print(\"\\nExample translation:\")\n",
        "                print(f\"Original: {row[gen_col][:100]}...\")\n",
        "                print(f\"Translated: {translated_gen[:100]}...\")\n",
        "                print(f\"Gold: {row[gold_col][:100]}...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row {idx}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(all_results)"
      ],
      "metadata": {
        "id": "3yIuZbO0H3kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = 'path to your csv file'\n",
        "df = pd.read_csv(csv_path, sep=',', encoding='utf-8', quotechar='\"', engine='python')"
      ],
      "metadata": {
        "id": "6w51WUkfH-rU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = evaluate_dataset(\n",
        "    df,\n",
        "    source_lang=source_lang,\n",
        "    target_lang=target_lang,\n",
        "    gen_col='generated_answer',\n",
        "    gold_col='gold_answer'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "29da425df850406789b4b9558465e7fb",
            "da38733309d6435a99c3f92d439acf18",
            "597864d2094d4e73b4ce61dc9a86b4f6",
            "911f74e3f0fd46f1ae454f08ed40d001",
            "cebc2c4f8374463b90e8d5115b34a91c",
            "3335c9516b644649a0b7e624154fc0eb",
            "f43a84ee3047430b8da25ad8415c77cc",
            "9f48b62e5c494b0ca964775c63afe879",
            "fff42b7617b74b459b11df77bd6bde03",
            "31daaa6c2d7d4175bd9bdeba297d0310",
            "2f928fa805ad41d7bc5f11f40d00f0bf"
          ]
        },
        "id": "1M9FbJswKC5j",
        "outputId": "d659929a-536c-4008-e604-b1370e5b6be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading translation model: Helsinki-NLP/opus-mt-vi-en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading evaluation models...\n",
            "Models loaded successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing:   0%|          | 0/160 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29da425df850406789b4b9558465e7fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing row 8: 'float' object is not subscriptable\n",
            "Translation error: index out of range in self\n",
            "\n",
            "Processed 20/160 samples\n",
            "Last sample results:\n",
            "sbert_similarity    : 0.7407\n",
            "bertscore_precision : 0.9112\n",
            "bertscore_recall    : 0.9177\n",
            "bertscore_f1        : 0.9145\n",
            "bleu_score          : 0.1284\n",
            "meteor_score        : 0.2783\n",
            "\n",
            "Example translation:\n",
            "Original: ibm content navigator v2.0.3 đang thêm phần mở rộng.dat vào tệp csv trong quá trình tải xuống tài li...\n",
            "Translated: The ibm content navigator v2.0.3 is adding the extension.dat to the Csv file in the download process...\n",
            "Gold: If the mime type of the document as shown in system properties in ICN is not text/csv, then Navigato...\n",
            "Translation error: index out of range in self\n",
            "\n",
            "Processed 40/160 samples\n",
            "Last sample results:\n",
            "sbert_similarity    : 0.5673\n",
            "bertscore_precision : 0.8749\n",
            "bertscore_recall    : 0.8508\n",
            "bertscore_f1        : 0.8626\n",
            "bleu_score          : 0.0157\n",
            "meteor_score        : 0.1388\n",
            "\n",
            "Example translation:\n",
            "Original: lỗi stackoverflow có thể xảy ra do một số nguyên nhân như mã không hợp lệ, lỗi trong mã, hoặc quá nh...\n",
            "Translated: stackive error can occur because of some reasons such as invalid code, error in code, or too many sc...\n",
            "Gold: When a stack overflow occurs, the amount of stack space required by the program exceeds what is conf...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1524 > 512). Running this sequence through the model will result in indexing errors\n",
            "Your input_length: 1524 is bigger than 0.9 * max_length: 1024. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation error: index out of range in self\n",
            "Error processing row 50: 'float' object is not subscriptable\n",
            "\n",
            "Processed 60/160 samples\n",
            "Last sample results:\n",
            "sbert_similarity    : 0.7743\n",
            "bertscore_precision : 0.8373\n",
            "bertscore_recall    : 0.8674\n",
            "bertscore_f1        : 0.8521\n",
            "bleu_score          : 0.0173\n",
            "meteor_score        : 0.1838\n",
            "\n",
            "Example translation:\n",
            "Original: sự khác biệt giữa db2 z/os v9.1 và db2 luw v10.5 fp7 là do sự thay đổi trong cách tính toán số lượng...\n",
            "Translated: The difference between db2 z/os v9.1 and db2 luw v10.5 fp7 is due to change in calculating the numbe...\n",
            "Gold: DB2 LUW precompile, prep write different code to DB2 z/OS?...\n",
            "\n",
            "Processed 80/160 samples\n",
            "Last sample results:\n",
            "sbert_similarity    : 0.7919\n",
            "bertscore_precision : 0.9200\n",
            "bertscore_recall    : 0.9177\n",
            "bertscore_f1        : 0.9189\n",
            "bleu_score          : 0.0924\n",
            "meteor_score        : 0.3243\n",
            "\n",
            "Example translation:\n",
            "Original: cách đơn giản nhất là dừng eventreader, mở và chỉnh sửa nó, nhấn nút \"clear state\", và khởi động lại...\n",
            "Translated: The simplest way is to stop eventreader, open and edit it, press the \"clearstate\" button, and restar...\n",
            "Gold: The simplest solution is to manually reset the EventReader StateChange value via the GUI. Stop the E...\n",
            "Translation error: index out of range in self\n",
            "\n",
            "Processed 100/160 samples\n",
            "Last sample results:\n",
            "sbert_similarity    : 0.5616\n",
            "bertscore_precision : 0.8974\n",
            "bertscore_recall    : 0.8534\n",
            "bertscore_f1        : 0.8749\n",
            "bleu_score          : 0.0096\n",
            "meteor_score        : 0.0989\n",
            "\n",
            "Example translation:\n",
            "Original: để khắc phục lỗi này, bạn cần tải xuống các tệp lại và thử cài đặt lần nữa. ngoài ra, có thể có các ...\n",
            "Translated: To fix this error, you need to download the files again and try to install them. Besides, there may ...\n",
            "Gold: When an IBM SPSS compressed image is launched, files compressed within it are extracted to the tempo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your input_length: 1418 is bigger than 0.9 * max_length: 1024. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation error: index out of range in self\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your input_length: 1498 is bigger than 0.9 * max_length: 1024. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation error: index out of range in self\n",
            "\n",
            "Processed 120/160 samples\n",
            "Last sample results:\n",
            "sbert_similarity    : 0.6497\n",
            "bertscore_precision : 0.8322\n",
            "bertscore_recall    : 0.9217\n",
            "bertscore_f1        : 0.8746\n",
            "bleu_score          : 0.0939\n",
            "meteor_score        : 0.4205\n",
            "\n",
            "Example translation:\n",
            "Original: ##begin_quote##ibm security bulletin: a vulnerability in ibm java runtime affects ibm websphere mq (...\n",
            "Translated: ##begin_quote##ibm security bulletin: a vulnerability in ibm java runtime affects ibm websphere mq (...\n",
            "Gold: CVEID: CVE-2016-3485 [http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3485]\n",
            "DESCRIPTION: An u...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your input_length: 1410 is bigger than 0.9 * max_length: 1024. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation error: index out of range in self\n",
            "\n",
            "Processed 140/160 samples\n",
            "Last sample results:\n",
            "sbert_similarity    : 0.5763\n",
            "bertscore_precision : 0.8534\n",
            "bertscore_recall    : 0.8226\n",
            "bertscore_f1        : 0.8377\n",
            "bleu_score          : 0.0196\n",
            "meteor_score        : 0.1192\n",
            "\n",
            "Example translation:\n",
            "Original: để bao gồm mô tả dài jobtask trong bảng jp, bạn cần thực hiện các bước sau: trong bảng \"integration\"...\n",
            "Translated: To cover the long description jobtask in the jp table, you need to take the following steps: in the ...\n",
            "Gold: Maximo 6.x MEA \n",
            "\n",
            "1. Go To Integration -> Integration Object \n",
            "\n",
            "On the Persistent Fields tab, exclude ...\n",
            "\n",
            "Processed 160/160 samples\n",
            "Last sample results:\n",
            "sbert_similarity    : 0.6603\n",
            "bertscore_precision : 0.8674\n",
            "bertscore_recall    : 0.8839\n",
            "bertscore_f1        : 0.8756\n",
            "bleu_score          : 0.0336\n",
            "meteor_score        : 0.7205\n",
            "\n",
            "Example translation:\n",
            "Original: các lỗ hổng trong openssl ảnh hưởng đến websphere mq 5.3 cho máy chủ hp nonstop (cve-2017-3735). các...\n",
            "Translated: The holes in openssl affect the web 420 mq 5.3 server hp nonstop (cve-2017-3735). The affected versi...\n",
            "Gold: All versions of WebSphere MQ 5.3 and MQ 8 for HPE NonStop Server...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = 'your output path'\n",
        "results_df.to_csv(output_path, index=False)\n",
        "print(f\"\\nResults saved to: {output_path}\")\n",
        "\n",
        "# Calculate and display correlations\n",
        "metrics = ['sbert_similarity', 'bertscore_precision', 'bertscore_recall',\n",
        "          'bertscore_f1', 'bleu_score', 'meteor_score']\n",
        "\n",
        "print(\"\\nFinal Average Scores:\")\n",
        "print(\"=\" * 50)\n",
        "for metric in metrics:\n",
        "    mean_score = results_df[metric].mean()\n",
        "    std_score = results_df[metric].std()\n",
        "    print(f\"{metric:20s}: {mean_score:.4f} (±{std_score:.4f})\")\n",
        "\n",
        "\n",
        "results_df.to_csv(output_path, index=False)\n",
        "print(f\"\\nResults saved to: {output_path}\")\n",
        "\n",
        "# Display correlation matrix\n",
        "correlation_matrix = results_df[metrics].corr().round(4)\n",
        "print(\"\\nCorrelation between metrics:\")\n",
        "print(\"=\" * 50)\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Optional: Sample of translations\n",
        "print(\"\\nSample Translations:\")\n",
        "print(\"=\" * 50)\n",
        "samples = results_df[['original_generated', 'gold_answer']].head(3)\n",
        "for idx, row in samples.iterrows():\n",
        "    print(f\"\\nExample {idx + 1}:\")\n",
        "    print(f\"Original: {row['original_generated'][:100]}...\")\n",
        "    #print(f\"Translated: {row['translated_generated'][:100]}...\")\n",
        "    print(f\"Gold: {row['gold_answer'][:100]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_-sVUpDKPgv",
        "outputId": "e498c11c-dc64-4206-deeb-0e634933c7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results saved to: /content/drive/MyDrive/Thesis_LCT/Datasets/TechQA_results/Viet/similarity_results_vimix.csv\n",
            "\n",
            "Final Average Scores:\n",
            "==================================================\n",
            "sbert_similarity    : 0.5227 (±0.1660)\n",
            "bertscore_precision : 0.8628 (±0.0301)\n",
            "bertscore_recall    : 0.8589 (±0.0413)\n",
            "bertscore_f1        : 0.8603 (±0.0289)\n",
            "bleu_score          : 0.0300 (±0.0475)\n",
            "meteor_score        : 0.1782 (±0.1457)\n",
            "\n",
            "Results saved to: /content/drive/MyDrive/Thesis_LCT/Datasets/TechQA_results/Viet/similarity_results_vimix.csv\n",
            "\n",
            "Correlation between metrics:\n",
            "==================================================\n",
            "                     sbert_similarity  bertscore_precision  bertscore_recall  \\\n",
            "sbert_similarity               1.0000               0.4816            0.3526   \n",
            "bertscore_precision            0.4816               1.0000            0.2708   \n",
            "bertscore_recall               0.3526               0.2708            1.0000   \n",
            "bertscore_f1                   0.5031               0.7233            0.8599   \n",
            "bleu_score                     0.3550               0.4356            0.5686   \n",
            "meteor_score                   0.4838               0.3873            0.6640   \n",
            "\n",
            "                     bertscore_f1  bleu_score  meteor_score  \n",
            "sbert_similarity           0.5031      0.3550        0.4838  \n",
            "bertscore_precision        0.7233      0.4356        0.3873  \n",
            "bertscore_recall           0.8599      0.5686        0.6640  \n",
            "bertscore_f1               1.0000      0.6358        0.6737  \n",
            "bleu_score                 0.6358      1.0000        0.7015  \n",
            "meteor_score               0.6737      0.7015        1.0000  \n",
            "\n",
            "Sample Translations:\n",
            "==================================================\n",
            "\n",
            "Example 1:\n",
            "Original: phiên bản ibm dashboard application services hub đã cài đặt là 3.1.0.3, nhưng yêu cầu phiên bản 3.1....\n",
            "Gold: Version 1.1.3.0 is a full refresh of Jazz for Service Management Version 1.1 Base with Modification ...\n",
            "\n",
            "Example 2:\n",
            "Original: để mở hồ sơ từ trình quản lý cấu hình p8 content engine (cmui) trên redhat linux 7.2, cần cài đặt cá...\n",
            "Gold: Install the missing libraries \"adwaita-gtk2-theme\" (32 and 64 bit) and \"adwaita-gtk3-theme\" 64 bit. ...\n",
            "\n",
            "Example 3:\n",
            "Original: cổng socket nào tôi nên sử dụng với netcool omnibus (noi)? cổng socket nào tôi nên sử dụng với netco...\n",
            "Gold: A new version of the Netcool/OMNIbus Socket Gateway will be available to download from August 6, 201...\n"
          ]
        }
      ]
    }
  ]
}